import os
import json
import requests
import datetime
import random
import base64
import re
import urllib.parse

# ================= é…ç½®åŒº =================
# ğŸ”´ è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ GitHub Pages åœ°å€
WEB_PAGE_URL = "https://liuxuisme.github.io/daily-soft-exam/" 
# =========================================

# ğŸ›ï¸ æ¶æ„å¸ˆä¸“ç”¨å¤§çº² (ä¿æŒä¸å˜ï¼Œè¦†ç›–å…¨è€ƒç‚¹)
SYLLABUS = {
    2: [
        "è¿ç­¹å­¦ä¸æ•°å­¦å»ºæ¨¡(çº¿æ€§è§„åˆ’/æœ€å¤§æµ/å†³ç­–è®º)", "æ“ä½œç³»ç»Ÿ(PV/æ­»é”/åµŒå…¥å¼OS)", 
        "æ•°æ®åº“(åˆ†å¸ƒå¼/Redis/åè§„èŒƒåŒ–)", "è®¡ç®—æœºç½‘ç»œ(SDN/CDN/IPv6)", 
        "ç³»ç»Ÿå¯é æ€§ä¸å®¹é”™æŠ€æœ¯"
    ],
    3: [
        "è½¯ä»¶æ¶æ„é£æ ¼(æ•°æ®æµ/C2/è°ƒç”¨è¿”å›)", "æ¶æ„è¯„ä¼°(ATAM/SAAM/è´¨é‡æ ‘)", 
        "è½¯ä»¶è´¨é‡å±æ€§(æˆ˜æœ¯ä¸è®¾è®¡)", "è®¾è®¡æ¨¡å¼(å·¥å‚/é€‚é…å™¨/ç­–ç•¥)", 
        "åŸºäºæ¶æ„çš„è½¯ä»¶å¼€å‘(ABSD/DSSA)"
    ],
    4: [
        "åˆ†å¸ƒå¼æ¶æ„(å¾®æœåŠ¡/SOA/RPC)", "äº‘åŸç”Ÿ(K8s/ServiceMesh)", 
        "å¤§æ•°æ®æ¶æ„(Lambda/Hadoop)", "ä¿¡æ¯å®‰å…¨æ¶æ„(PKI/åŒºå—é“¾)", 
        "é«˜å¹¶å‘Webæ¶æ„è®¾è®¡"
    ],
    5: [
        "å†å¹´çœŸé¢˜é›†è®­(ç»¼åˆçŸ¥è¯†)", "æ¡ˆä¾‹åˆ†æä¸“é¡¹(ç³»ç»Ÿè®¾è®¡)", 
        "è®ºæ–‡å†™ä½œ(æ¶æ„/å¾®æœåŠ¡/æ•°æ®)", "è€ƒå‰æŸ¥æ¼è¡¥ç¼º"
    ]
}

def get_today_topic():
    today = datetime.datetime.now()
    month = today.month
    topics = SYLLABUS.get(month, SYLLABUS[5])
    random.seed(today.strftime("%Y%m%d")) 
    return random.choice(topics)

def get_ai_content(topic):
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key: return None

    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key={api_key}"
    
    # ğŸ“ ä¼˜åŒ– Promptï¼šæ˜ç¡®ç¦æ­¢ LaTeX å•åæ–œæ ï¼Œé˜²æ­¢ JSON ç‚¸è£‚
    prompt_text = f"""
    ä½ æ˜¯ä¸€ä½**è½¯è€ƒç³»ç»Ÿæ¶æ„è®¾è®¡å¸ˆï¼ˆé«˜çº§ï¼‰é‡‘ç‰ŒåŸ¹è®­è®²å¸ˆ**ã€‚
    ä»Šå¤©æ˜¯å¤‡è€ƒå†²åˆºæ—¥ï¼Œä¸»é¢˜æ˜¯ã€{topic}ã€‘ã€‚
    
    è¯·ä¸¥æ ¼åŸºäº**å†å¹´çœŸé¢˜ï¼ˆ2015-2025ï¼‰**ï¼Œç”Ÿæˆä¸€ä»½åŒ…å«"å­¦ã€è®°ã€ç»ƒ"çš„å…¨æ–¹ä½å­¦ä¹ æ•°æ®ã€‚
    
    ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘ï¼š
    1. è¿”å›çº¯ JSON æ ¼å¼ã€‚
    2. **ä¸¥ç¦åœ¨å­—ç¬¦ä¸²ä¸­ä½¿ç”¨æœªè½¬ä¹‰çš„ LaTeX åæ–œæ ï¼ˆå¦‚ \sum, \alphaï¼‰**ã€‚è¯·ä½¿ç”¨çº¯æ–‡æœ¬ç¬¦å·ä»£æ›¿ï¼ˆå¦‚ sum, alphaï¼‰ï¼Œæˆ–è€…ä½¿ç”¨ markdown ä»£ç å—ã€‚
    3. å¦‚æœå¿…é¡»åŒ…å«å…¬å¼ï¼Œè¯·ç¡®ä¿åæ–œæ è¢«è½¬ä¹‰ï¼ˆä¾‹å¦‚å†™æˆ \\sum è€Œä¸æ˜¯ \sumï¼‰ã€‚
    
    JSON ç»“æ„å¦‚ä¸‹ï¼š
    {{
        "topic": "{topic}",
        "core_concept": "æ ¸å¿ƒè€ƒç‚¹æç‚¼ï¼ˆMarkdownï¼‰ã€‚åˆ—å‡º3-5ä¸ªè€ƒç‚¹ã€‚",
        "knowledge_explanation": "æ·±åº¦ç²¾è®²ï¼ˆMarkdownï¼‰ã€‚åŒ…å«åŸç†ã€**è®°å¿†å£è¯€**æˆ–å¯¹æ¯”è¡¨æ ¼ã€‚å¦‚æœæ¶‰åŠæ•°å­¦å…¬å¼ï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„æ–‡æœ¬æè¿°ã€‚",
        "essay_guide": "è®ºæ–‡ä¸æ¡ˆä¾‹æŒ‡å¯¼ï¼ˆMarkdownï¼‰ã€‚",
        "questions": [
            {{
                "question": "é¢˜å¹² [å¹´ä»½]",
                "options": ["A. x", "B. x", "C. x", "D. x"],
                "answer": "B",
                "analysis": "è§£æã€‚"
            }}
        ]
    }}
    è¯·ç”Ÿæˆ 10 é“é¢˜ã€‚
    """
    
    payload = { "contents": [{ "parts": [{"text": prompt_text}] }] }
    headers = {'Content-Type': 'application/json'}

    try:
        print(f"ğŸš€ [æ¶æ„å¸ˆå¤‡æˆ˜] æ­£åœ¨ç”Ÿæˆã€{topic}ã€‘çš„å…¨å¥—èµ„æ–™(10é¢˜+ç²¾è®²)...")
        resp = requests.post(url, headers=headers, json=payload, timeout=90)
        
        if resp.status_code != 200:
            print(f"âŒ AI è¯·æ±‚å¤±è´¥: {resp.text}")
            return None
            
        result = resp.json()
        text = result['candidates'][0]['content']['parts'][0]['text'].strip()
        
        # --- ğŸ§¹ æ•°æ®æ¸…æ´—åŒº (æ ¸å¿ƒä¿®å¤) ---
        # 1. å»é™¤ Markdown ä»£ç å—æ ‡è®°
        text = text.replace("```json", "").replace("```", "").strip()
        
        # 2. æ­£åˆ™ä¿®å¤ï¼šå°†æ‰€æœ‰â€œä¸åˆæ³•çš„åæ–œæ â€æ›¿æ¢ä¸ºâ€œåŒåæ–œæ â€
        # é€»è¾‘ï¼šæŸ¥æ‰¾æ‰€æœ‰å¹¶ä¸æ˜¯ç´§è·Ÿåœ¨ " \ / b f n r t u è¿™é‡Œçš„åæ–œæ 
        # è¿™æ ·å¯ä»¥ä¿ç•™ \n \t \" ç­‰åˆæ³•è½¬ä¹‰ï¼Œä¿®å¤ \s \a \l ç­‰éæ³•è½¬ä¹‰
        try:
            return json.loads(text)
        except json.decoder.JSONDecodeError:
            print("âš ï¸ æ£€æµ‹åˆ° JSON æ ¼å¼éæ³•ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤ LaTeX åæ–œæ ...")
            # è¿™æ˜¯ä¸€ä¸ªå¼ºåŠ›ä¿®å¤æ­£åˆ™ï¼šæŠŠæ‰€æœ‰ \ å˜æˆ \\ (é™¤äº†å·²ç»æ˜¯è½¬ä¹‰ç¬¦çš„)
            # ä½†ç®€å•ç‚¹ï¼Œæˆ‘ä»¬ç›´æ¥æŠŠå•ä¸ª \ æ›¿æ¢ä¸º / æˆ–è€…ç›´æ¥åŒå†™ï¼Œè¿™é‡Œç”¨ä¿å®ˆç­–ç•¥ï¼š
            # æ›¿æ¢æ‰æ‰€æœ‰å¯¼è‡´æŠ¥é”™çš„å•æ–œæ 
            text = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', text)
            return json.loads(text)

    except Exception as e:
        print(f"âŒ è§£æå‡ºé”™ (åŸå§‹å†…å®¹å¯èƒ½åŒ…å«éæ³•å­—ç¬¦): {e}")
        # æ‰“å°å‡ºå‰100ä¸ªå­—ç¬¦æ–¹ä¾¿è°ƒè¯•
        if 'text' in locals(): print(f"Raw text start: {text[:100]}...")
        return None

def save_to_file(data):
    date_str = datetime.datetime.now().strftime("%Y-%m-%d")
    os.makedirs("docs/data", exist_ok=True)
    file_path = f"docs/data/{date_str}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return date_str

def send_dingtalk(date_str, data):
    webhook = os.environ.get("DINGTALK_WEBHOOK")
    if not webhook: return

    full_url = f"{WEB_PAGE_URL}/index.html?date={date_str}"
    print(f"ğŸ”— ç”Ÿæˆé“¾æ¥: {full_url}")

    text = f"""### ğŸ›ï¸ æ¶æ„å¸ˆå¤‡è€ƒï¼š{data['topic']}

**ğŸ”¥ ä»Šæ—¥ä»»åŠ¡æ¸…å•ï¼š**
1. ğŸ§  **æ ¸å¿ƒç²¾è®²**ï¼šåŸç† + è®°å¿†å£è¯€
2. ğŸ“ **è®ºæ–‡/æ¡ˆä¾‹**ï¼šå†™ä½œä¸è§£é¢˜æŠ€å·§
3. âš”ï¸ **çœŸé¢˜å®æˆ˜**ï¼š{len(data['questions'])} é“é«˜é¢‘çœŸé¢˜

---
ğŸ‘‡ **ç‚¹å‡»å¼€å§‹æ·±åº¦å­¦ä¹ **
[ğŸ‘‰ è¿›å…¥ç‰¹è®­ç³»ç»Ÿ]({full_url})

*(é“¾æ¥è‹¥æ— æ³•æ‰“å¼€ï¼Œè¯·å¤åˆ¶åˆ°æµè§ˆå™¨è®¿é—®)*
"""
    payload = {
        "msgtype": "markdown",
        "markdown": { "title": f"æ¶æ„å¸ˆç‰¹è®­ï¼š{data['topic']}", "text": text }
    }
    requests.post(webhook, json=payload)

if __name__ == "__main__":
    topic = get_today_topic()
    data = get_ai_content(topic)
    if data:
        date_str = save_to_file(data)
        send_dingtalk(date_str, data)
    else:
        exit(1)
