import os
import json
import requests
import datetime
import random
import re
import urllib.parse

# ================= é…ç½®åŒº =================
# 1. ä½ çš„ GitHub Pages åœ°å€ (æ·±åº¦ç‰¹è®­)
WEB_PAGE_URL = "https://liuxuisme.github.io/daily-soft-exam/" 
# 2. è½¯è€ƒè¾¾äººåœ°å€ (æ¯æ—¥ä¸€ç»ƒ)
EXTERNAL_URL = "https://ruankaodaren.com/exam/#/answertest/answertest?reset=0&type=8"
# =========================================

# ğŸ›ï¸ æ¶æ„å¸ˆä¸“ç”¨å¤§çº²
SYLLABUS = {
    2: [
        "æ“ä½œç³»ç»Ÿ-PVæ“ä½œä¸å‰è¶‹å›¾", "æ“ä½œç³»ç»Ÿ-æ­»é”ä¸é“¶è¡Œå®¶ç®—æ³•", 
        "æ“ä½œç³»ç»Ÿ-é¡µå¼å­˜å‚¨ä¸ç¼ºé¡µä¸­æ–­è®¡ç®—", "æ“ä½œç³»ç»Ÿ-æ–‡ä»¶ç´¢å¼•ä¸ä½ç¤ºå›¾",
        "æ“ä½œç³»ç»Ÿ-ç£ç›˜è°ƒåº¦ä¸åµŒå…¥å¼RTOS",
        "æ•°æ®åº“-ä¸‰èŒƒå¼ä¸åè§„èŒƒåŒ–è®¾è®¡", "æ•°æ®åº“-åˆ†å¸ƒå¼æ•°æ®åº“(2PC/CAP/BASE)", 
        "æ•°æ®åº“-Redisç¼“å­˜ç­–ç•¥ä¸æ•°æ®ä¸€è‡´æ€§", "æ•°æ®åº“-æ•°æ®ä»“åº“ä¸å•†ä¸šæ™ºèƒ½(BI)",
        "è®¡ç®—æœºç½‘ç»œ-SDNè½¯ä»¶å®šä¹‰ç½‘ç»œ", "è®¡ç®—æœºç½‘ç»œ-CDNå†…å®¹åˆ†å‘ä¸è¾¹ç¼˜è®¡ç®—", 
        "è®¡ç®—æœºç½‘ç»œ-ç½‘ç»œå­˜å‚¨(DAS/NAS/SAN)", "è®¡ç®—æœºç½‘ç»œ-IPv6ä¸ç½‘ç»œè§„åˆ’",
        "æ•°å­¦-çº¿æ€§è§„åˆ’ä¸å•çº¯å½¢æ³•", "æ•°å­¦-æœ€å¤§æµä¸æœ€å°å‰²", 
        "æ•°å­¦-å†³ç­–è®º(æœ€å¤§æœ€å°/åæ‚”å€¼)", "æ•°å­¦-å›¾è®ºä¸å…³é”®è·¯å¾„æ³•(CPM)"
    ],
    3: [
        "æ¶æ„é£æ ¼-æ•°æ®æµé£æ ¼", "æ¶æ„é£æ ¼-è°ƒç”¨è¿”å›",
        "æ¶æ„é£æ ¼-ç‹¬ç«‹æ„ä»¶", "æ¶æ„é£æ ¼-è™šæ‹Ÿæœºä¸è§£é‡Šå™¨",
        "æ¶æ„é£æ ¼-C2é£æ ¼ä¸ä»“åº“é£æ ¼",
        "æ¶æ„è¯„ä¼°-ATAM", "æ¶æ„è¯„ä¼°-SAAM",
        "æ¶æ„è¯„ä¼°-CBAM", "è´¨é‡å±æ€§-æ•ˆç”¨æ ‘ä¸è´¨é‡åœºæ™¯",
        "è´¨é‡å±æ€§-æˆ˜æœ¯(å¯ç”¨æ€§/æ€§èƒ½/å®‰å…¨æ€§)",
        "è®¾è®¡æ¨¡å¼-åˆ›å»ºå‹", "è®¾è®¡æ¨¡å¼-ç»“æ„å‹",
        "è®¾è®¡æ¨¡å¼-è¡Œä¸ºå‹",
        "å¼€å‘æ–¹æ³•-ABSD", "å¼€å‘æ–¹æ³•-DSSA"
    ],
    4: [
        "åˆ†å¸ƒå¼-å¾®æœåŠ¡æ¶æ„æ‹†åˆ†", "åˆ†å¸ƒå¼-SOAä¸ESB",
        "åˆ†å¸ƒå¼-RPCä¸RESTful", "åˆ†å¸ƒå¼-æ¶ˆæ¯é˜Ÿåˆ—",
        "äº‘åŸç”Ÿ-Dockerä¸K8s", "äº‘åŸç”Ÿ-ServiceMesh",
        "äº‘åŸç”Ÿ-Serverless",
        "å¤§æ•°æ®-Lambdaä¸Kappa", "å¤§æ•°æ®-Hadoopä¸Spark",
        "å®‰å…¨æ¶æ„-PKIä¸æ•°å­—ç­¾å", "å®‰å…¨æ¶æ„-è®¿é—®æ§åˆ¶",
        "å®‰å…¨æ¶æ„-åŒºå—é“¾",
        "é«˜å¹¶å‘-è´Ÿè½½å‡è¡¡", "é«˜å¹¶å‘-è¯»å†™åˆ†ç¦»ä¸åˆ†åº“åˆ†è¡¨"
    ],
    5: [
        "çœŸé¢˜é›†è®­-ç»¼åˆçŸ¥è¯†å†å¹´é”™é¢˜", "æ¡ˆä¾‹åˆ†æ-ç³»ç»Ÿæ¶æ„è®¾è®¡è¯•é¢˜",
        "æ¡ˆä¾‹åˆ†æ-UMLå»ºæ¨¡ä¸æ•°æ®åº“è®¾è®¡", "æ¡ˆä¾‹åˆ†æ-åµŒå…¥å¼ç³»ç»Ÿè®¾è®¡",
        "è®ºæ–‡å†™ä½œ-è®ºå¾®æœåŠ¡æ¶æ„çš„è®¾è®¡", "è®ºæ–‡å†™ä½œ-è®ºè½¯ä»¶æ¶æ„é£æ ¼",
        "è®ºæ–‡å†™ä½œ-è®ºç³»ç»Ÿå¯é æ€§è®¾è®¡", "è®ºæ–‡å†™ä½œ-è®ºæ•°æ®æ¹–ä¸æ¹–ä»“ä¸€ä½“"
    ]
}

# çŠ¶æ€æ–‡ä»¶è·¯å¾„
STATUS_FILE = "docs/data/syllabus_status.json"

def get_smart_topic():
    today = datetime.datetime.now()
    current_month = today.month
    default_topics = SYLLABUS.get(5)
    
    status = {}
    if os.path.exists(STATUS_FILE):
        try:
            with open(STATUS_FILE, "r", encoding="utf-8") as f:
                status = json.load(f)
        except:
            status = {}
    
    saved_month = status.get("month", -1)
    pending_list = status.get("pending", [])
    
    if saved_month != current_month:
        pending_list = SYLLABUS.get(current_month, default_topics).copy()
        random.shuffle(pending_list)
        status["month"] = current_month
    
    if not pending_list:
        pending_list = SYLLABUS.get(current_month, default_topics).copy()
        random.shuffle(pending_list)
    
    today_topic = pending_list.pop(0)
    
    status["pending"] = pending_list
    os.makedirs(os.path.dirname(STATUS_FILE), exist_ok=True)
    with open(STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump(status, f, ensure_ascii=False, indent=2)
        
    return today_topic

def get_ai_content(topic):
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key: return None

    # ä½¿ç”¨ Gemini 2.5 Flash
    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key={api_key}"
    
    prompt_text = f"""
    ä½ æ˜¯ä¸€ä½**è½¯è€ƒç³»ç»Ÿæ¶æ„è®¾è®¡å¸ˆï¼ˆé«˜çº§ï¼‰é˜…å·ä¸“å®¶**ã€‚
    ä»Šå¤©æ˜¯å¤‡è€ƒå†²åˆºæ—¥ï¼Œå…·ä½“ç»†åˆ†è€ƒç‚¹æ˜¯ã€{topic}ã€‘ã€‚
    
    è¯·ä¸¥æ ¼åŸºäº**å†å¹´çœŸé¢˜ï¼ˆ2015-2025ï¼‰**ï¼Œç”Ÿæˆå…¨æ–¹ä½å­¦ä¹ æ•°æ®ã€‚
    
    ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘ï¼š
    1. è¿”å›çº¯ JSON æ ¼å¼ã€‚
    2. **ä¸¥ç¦åœ¨å­—ç¬¦ä¸²ä¸­ä½¿ç”¨æœªè½¬ä¹‰çš„ LaTeX åæ–œæ **ã€‚è¯·ä½¿ç”¨çº¯æ–‡æœ¬ç¬¦å·æˆ–è½¬ä¹‰åæ–œæ  (\\sum)ã€‚
    3. æ‰€æœ‰çš„æ¢è¡Œè¯·ä½¿ç”¨ \\nï¼Œä¸è¦ç›´æ¥æ¢è¡Œã€‚
    
    JSON ç»“æ„å¦‚ä¸‹ï¼š
    {{
        "topic": "{topic}",
        "core_concept": "æ ¸å¿ƒè€ƒç‚¹æç‚¼ï¼ˆMarkdownï¼‰ã€‚åˆ—å‡º3ä¸ªå…³é”®æ¦‚å¿µæˆ–å…¬å¼ã€‚",
        "knowledge_explanation": "æ·±åº¦ç²¾è®²ï¼ˆMarkdownï¼‰ã€‚åŒ…å«åŸç†ã€**è®°å¿†å£è¯€**æˆ–å¯¹æ¯”è¡¨æ ¼ã€‚",
        "essay_guide": "è®ºæ–‡ä¸æ¡ˆä¾‹æŒ‡å¯¼ï¼ˆMarkdownï¼‰ã€‚",
        "questions": [
            {{
                "question": "é¢˜å¹² [å¹´ä»½]",
                "options": ["A. x", "B. x", "C. x", "D. x"],
                "answer": "B",
                "analysis": "è§£æã€‚"
            }}
        ]
    }}
    è¯·ç”Ÿæˆ 10 é“é¢˜ã€‚
    """
    
    payload = { "contents": [{ "parts": [{"text": prompt_text}] }] }
    headers = {'Content-Type': 'application/json'}

    try:
        print(f"ğŸš€ æ­£åœ¨è°ƒç”¨ AI ç”Ÿæˆå†…å®¹...")
        resp = requests.post(url, headers=headers, json=payload, timeout=120)
        
        if resp.status_code != 200:
            print(f"âŒ AI è¯·æ±‚å¤±è´¥: {resp.text}")
            return None
            
        result = resp.json()
        text = result['candidates'][0]['content']['parts'][0]['text'].strip()
        text = text.replace("```json", "").replace("```", "").strip()
        
        try:
            return json.loads(text, strict=False)
        except json.decoder.JSONDecodeError:
            text = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', text)
            return json.loads(text, strict=False)

    except Exception as e:
        print(f"âŒ è§£æå‡ºé”™: {e}")
        return None

def save_to_file(data):
    date_str = datetime.datetime.now().strftime("%Y-%m-%d")
    os.makedirs("docs/data", exist_ok=True)
    file_path = f"docs/data/{date_str}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return date_str

def send_dingtalk(date_str, data):
    webhook_env = os.environ.get("DINGTALK_WEBHOOK")
    if not webhook_env: return

    # æ”¯æŒå¤šä¸ª Webhook
    webhooks = [w.strip() for w in webhook_env.split(',') if w.strip()]

    # ç”Ÿæˆç‰¹è®­é“¾æ¥
    internal_url = f"{WEB_PAGE_URL}/index.html?date={date_str}"
    
    # è®¡ç®—å€’è®¡æ—¶
    today = datetime.datetime.now()
    exam_date = datetime.datetime(today.year, 5, 24)
    days_left = (exam_date - today).days + 1
    if days_left < 0: days_left = 0

    msg_title = f"è·ç¦»è½¯è€ƒè¿˜æœ‰ {days_left} å¤©"

    # ==========================================
    # ğŸŒŸ æ ¸å¿ƒä¿®æ”¹ï¼šåˆå¹¶ä¸¤ä¸ªä»»åŠ¡çš„ Markdown æ–‡æ¡ˆ
    # ==========================================
    text = f"""### â³ {msg_title}

**ä»Šæ—¥ç‰¹è®­ï¼š{data['topic']}**

---
**ä»»åŠ¡ Aï¼šæ·±åº¦ç‰¹è®­ (AIç²¾è®²)**
10 é“ä¸“é¡¹æ¨¡æ‹Ÿé¢˜[ğŸ‘‰ è¿›å…¥ç‰¹è®­ç³»ç»Ÿ ]({internal_url})

---
**ä»»åŠ¡ Bï¼šæ¯æ—¥ä¸€ç»ƒ (å¼€æºç«™ç‚¹)**
è½¯è€ƒå†å¹´çœŸé¢˜åº“[ğŸ‘‰ è¿›å…¥æ¯æ—¥ä¸€ç»ƒ ]({EXTERNAL_URL})
"""
    
    payload = {
        "msgtype": "markdown",
        "markdown": { "title": msg_title, "text": text }
    }

    print(f"ğŸ“¢ å‡†å¤‡æ¨é€åˆ° {len(webhooks)} ä¸ªç¾¤...")
    for webhook in webhooks:
        try:
            requests.post(webhook, json=payload, timeout=10)
        except Exception:
            pass

if __name__ == "__main__":
    topic = get_smart_topic()
    data = get_ai_content(topic)
    
    if data:
        date_str = save_to_file(data)
        send_dingtalk(date_str, data)
    else:
        print("âŒ ä»»åŠ¡å¤±è´¥")
        exit(1)
