import os
import json
import requests
import datetime
import random
import base64
import urllib.parse

# ================= é…ç½®åŒº =================
# ğŸ”´ è¯·æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ GitHub Pages åœ°å€
WEB_PAGE_URL = "https://liuxuisme.github.io/daily-soft-exam/" 
# =========================================

# ğŸ›ï¸ æ¶æ„å¸ˆä¸“ç”¨å¤§çº² (ä¿æŒä¸å˜ï¼Œè¦†ç›–å…¨è€ƒç‚¹)
SYLLABUS = {
    2: [
        "è¿ç­¹å­¦ä¸æ•°å­¦å»ºæ¨¡(çº¿æ€§è§„åˆ’/æœ€å¤§æµ/å†³ç­–è®º)", "æ“ä½œç³»ç»Ÿ(PV/æ­»é”/åµŒå…¥å¼OS)", 
        "æ•°æ®åº“(åˆ†å¸ƒå¼/Redis/åè§„èŒƒåŒ–)", "è®¡ç®—æœºç½‘ç»œ(SDN/CDN/IPv6)", 
        "ç³»ç»Ÿå¯é æ€§ä¸å®¹é”™æŠ€æœ¯"
    ],
    3: [
        "è½¯ä»¶æ¶æ„é£æ ¼(æ•°æ®æµ/C2/è°ƒç”¨è¿”å›)", "æ¶æ„è¯„ä¼°(ATAM/SAAM/è´¨é‡æ ‘)", 
        "è½¯ä»¶è´¨é‡å±æ€§(æˆ˜æœ¯ä¸è®¾è®¡)", "è®¾è®¡æ¨¡å¼(å·¥å‚/é€‚é…å™¨/ç­–ç•¥)", 
        "åŸºäºæ¶æ„çš„è½¯ä»¶å¼€å‘(ABSD/DSSA)"
    ],
    4: [
        "åˆ†å¸ƒå¼æ¶æ„(å¾®æœåŠ¡/SOA/RPC)", "äº‘åŸç”Ÿ(K8s/ServiceMesh)", 
        "å¤§æ•°æ®æ¶æ„(Lambda/Hadoop)", "ä¿¡æ¯å®‰å…¨æ¶æ„(PKI/åŒºå—é“¾)", 
        "é«˜å¹¶å‘Webæ¶æ„è®¾è®¡"
    ],
    5: [
        "å†å¹´çœŸé¢˜é›†è®­(ç»¼åˆçŸ¥è¯†)", "æ¡ˆä¾‹åˆ†æä¸“é¡¹(ç³»ç»Ÿè®¾è®¡)", 
        "è®ºæ–‡å†™ä½œ(æ¶æ„/å¾®æœåŠ¡/æ•°æ®)", "è€ƒå‰æŸ¥æ¼è¡¥ç¼º"
    ]
}

def get_today_topic():
    today = datetime.datetime.now()
    month = today.month
    topics = SYLLABUS.get(month, SYLLABUS[5])
    random.seed(today.strftime("%Y%m%d")) 
    return random.choice(topics)

def get_ai_content(topic):
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key: return None

    url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key={api_key}"
    
    # ğŸ”¥ v2.1 Prompt: 10é¢˜ + æ·±åº¦è®²è§£
    prompt_text = f"""
    ä½ æ˜¯ä¸€ä½**è½¯è€ƒç³»ç»Ÿæ¶æ„è®¾è®¡å¸ˆï¼ˆé«˜çº§ï¼‰é‡‘ç‰ŒåŸ¹è®­è®²å¸ˆ**ã€‚
    ä»Šå¤©æ˜¯å¤‡è€ƒå†²åˆºæ—¥ï¼Œä¸»é¢˜æ˜¯ã€{topic}ã€‘ã€‚
    
    è¯·ä¸¥æ ¼åŸºäº**å†å¹´çœŸé¢˜ï¼ˆ2015-2024ï¼‰**ï¼Œç”Ÿæˆä¸€ä»½åŒ…å«"å­¦ã€è®°ã€ç»ƒ"çš„å…¨æ–¹ä½å­¦ä¹ æ•°æ®ã€‚
    
    è¯·è¿”å›ä¸€ä¸ªçº¯ JSON å¯¹è±¡ï¼Œç»“æ„å¦‚ä¸‹ï¼š
    
    1. "topic": "{topic}"
    2. "core_concept": "æ ¸å¿ƒè€ƒç‚¹æç‚¼ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚åˆ—å‡ºè¯¥é¢†åŸŸçš„3-5ä¸ªé«˜é¢‘è€ƒç‚¹åè¯æˆ–å…¬å¼ï¼Œç®€æ´æ˜äº†ï¼Œé€‚åˆå¿«é€Ÿå›é¡¾ã€‚"
    3. "knowledge_explanation": "æ·±åº¦ç²¾è®²ä¸è®°å¿†ï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚è¿™æ˜¯é‡ç‚¹ã€‚è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è¯¦ç»†è®²è§£ä¸Šè¿°è€ƒç‚¹çš„åŸç†ã€‚**å¿…é¡»åŒ…å«ä¸€ä¸ªâ€˜è®°å¿†å£è¯€â€™æˆ–â€˜å¯¹æ¯”è¡¨æ ¼â€™æ¥å¸®åŠ©è®°å¿†**ã€‚å¦‚æœæœ‰æŠ€æœ¯éš¾ç‚¹ï¼Œè¯·ä¸¾ä¾‹è¯´æ˜ã€‚"
    4. "essay_guide": "è®ºæ–‡ä¸æ¡ˆä¾‹æŒ‡å¯¼ã€‚å¦‚æœè¯¥ä¸»é¢˜é€‚åˆå†™è®ºæ–‡ï¼Œè¯·ç»™å‡º300å­—çš„å†™ä½œæ¶æ„ï¼ˆæ‘˜è¦+æ­£æ–‡è®ºç‚¹ï¼‰ï¼›å¦‚æœä¸é€‚åˆï¼Œè¯·æŒ‡å‡ºä¸‹åˆæ¡ˆä¾‹åˆ†æé¢˜çš„å¸¸è§è€ƒæ³•ï¼ˆå¦‚ï¼šå¡«ç©ºã€æ”¹é”™ã€ç”»å›¾ï¼‰ã€‚"
    5. "questions": ä¸€ä¸ªåŒ…å« **10** é“å†å¹´çœŸé¢˜ï¼ˆæˆ–é«˜åº¦æ‹ŸçœŸé¢˜ï¼‰çš„æ•°ç»„ã€‚
       - "question": "é¢˜å¹²ï¼ˆå°½é‡æ ‡æ³¨å¹´ä»½ï¼Œå¦‚ [2022]ï¼‰"
       - "options": ["A. x", "B. x", "C. x", "D. x"]
       - "answer": "B"
       - "analysis": "è§£æã€‚è§£é‡Šæ­£ç¡®åŸå› ï¼Œå¹¶æŒ‡å‡ºå¹²æ‰°é¡¹ä¸ºä»€ä¹ˆé”™ã€‚"
       
    æ³¨æ„ï¼šå†…å®¹è¦æ·±æµ…ç»“åˆï¼Œæ—¢è¦æœ‰å®è§‚æ¶æ„æ€ç»´ï¼Œåˆè¦æœ‰å…·ä½“çš„åšé¢˜æŠ€å·§ã€‚
    """
    
    payload = { "contents": [{ "parts": [{"text": prompt_text}] }] }
    headers = {'Content-Type': 'application/json'}

    try:
        print(f"ğŸš€ [æ¶æ„å¸ˆå¤‡æˆ˜] æ­£åœ¨ç”Ÿæˆã€{topic}ã€‘çš„å…¨å¥—èµ„æ–™(10é¢˜+ç²¾è®²)...")
        resp = requests.post(url, headers=headers, json=payload, timeout=90) # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºç”Ÿæˆ10é¢˜è¾ƒæ…¢
        
        if resp.status_code != 200:
            print(f"âŒ AI è¯·æ±‚å¤±è´¥: {resp.text}")
            return None
            
        result = resp.json()
        text = result['candidates'][0]['content']['parts'][0]['text'].strip()
        text = text.replace("```json", "").replace("```", "").strip()
        return json.loads(text)

    except Exception as e:
        print(f"âŒ å‡ºé”™: {e}")
        return None

def save_to_file(data):
    date_str = datetime.datetime.now().strftime("%Y-%m-%d")
    os.makedirs("docs/data", exist_ok=True)
    file_path = f"docs/data/{date_str}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return date_str

def send_dingtalk(date_str, data):
    webhook = os.environ.get("DINGTALK_WEBHOOK")
    if not webhook: return

    full_url = f"{WEB_PAGE_URL}/index.html?date={date_str}"
    print(f"ğŸ”— ç”Ÿæˆé“¾æ¥: {full_url}")

    text = f"""### ğŸ›ï¸ æ¶æ„å¸ˆå¤‡è€ƒï¼š{data['topic']}

**ğŸ”¥ ä»Šæ—¥ä»»åŠ¡æ¸…å•ï¼š**
1. ğŸ§  **æ ¸å¿ƒç²¾è®²**ï¼šåŸç† + è®°å¿†å£è¯€
2. ğŸ“ **è®ºæ–‡/æ¡ˆä¾‹**ï¼šå†™ä½œä¸è§£é¢˜æŠ€å·§
3. âš”ï¸ **çœŸé¢˜å®æˆ˜**ï¼š{len(data['questions'])} é“é«˜é¢‘çœŸé¢˜

---
ğŸ‘‡ **ç‚¹å‡»å¼€å§‹æ·±åº¦å­¦ä¹ **
[ğŸ‘‰ è¿›å…¥ç‰¹è®­ç³»ç»Ÿ]({full_url})

*(é“¾æ¥è‹¥æ— æ³•æ‰“å¼€ï¼Œè¯·å¤åˆ¶åˆ°æµè§ˆå™¨è®¿é—®)*
"""
    payload = {
        "msgtype": "markdown",
        "markdown": { "title": f"æ¶æ„å¸ˆç‰¹è®­ï¼š{data['topic']}", "text": text }
    }
    requests.post(webhook, json=payload)

if __name__ == "__main__":
    topic = get_today_topic()
    data = get_ai_content(topic)
    if data:
        date_str = save_to_file(data)
        send_dingtalk(date_str, data)
    else:
        exit(1)
